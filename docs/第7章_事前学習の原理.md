# 第7章：事前学習の原理

この章では、LLMの**事前学習（Pre-training）**の詳細を学びます。ゼロから大規模モデルを訓練する際の理論と実践を理解していきます。

---

## 7.1 最尤推定と言語モデリング

### 7.1.1 言語モデリングの目的

**目標：**

訓練データの確率分布を学習する

$$P_\theta(w_1, w_2, \ldots, w_n) \approx P_{\text{data}}(w_1, w_2, \ldots, w_n)$$

**最尤推定（Maximum Likelihood Estimation, MLE）：**

$$\theta^* = \arg\max_\theta \prod_{(w_1,\ldots,w_n) \in \mathcal{D}} P_\theta(w_1, \ldots, w_n)$$

**対数尤度：**

$$\mathcal{L}(\theta) = \sum_{(w_1,\ldots,w_n) \in \mathcal{D}} \log P_\theta(w_1, \ldots, w_n)$$

**連鎖律を適用：**

$$\mathcal{L}(\theta) = \sum_{(w_1,\ldots,w_n) \in \mathcal{D}} \sum_{t=1}^{n} \log P_\theta(w_t | w_{<t})$$

### 7.1.2 ネガティブ対数尤度

**損失関数として：**

$$\mathcal{L}_{\text{NLL}} = -\frac{1}{N}\sum_{i=1}^{N} \log P_\theta(w_i | w_{<i})$$

ここで $N$ は総トークン数

**直感的理解：**

> 「正解のトークンに高い確率を割り当てる」ほど損失が小さい

**例：**

```
文脈: "猫が魚を"
正解: "食べる"

モデルの予測分布:
  食べる: 0.8  → -log(0.8) = 0.22 (損失小)
  見る:   0.1
  追う:   0.05
  ...

もし予測が悪ければ:
  食べる: 0.1  → -log(0.1) = 2.30 (損失大)
```

### 7.1.3 実装の詳細

**ソフトマックス関数：**

$$P_\theta(w_t = k | w_{<t}) = \frac{\exp(z_k)}{\sum_{j=1}^{V} \exp(z_j)}$$

ここで：
- $z = \mathbf{Wh} + \mathbf{b}$：ロジット
- $h$：Transformerの最終層の隠れ状態
- $V$：語彙サイズ

**計算の流れ：**

```
入力トークン列
    ↓
Transformer (エンコード)
    ↓
隠れ状態 h ∈ ℝ^(d_model)
    ↓
線形変換 W ∈ ℝ^(V × d_model)
    ↓
ロジット z ∈ ℝ^V
    ↓
Softmax
    ↓
確率分布 P ∈ ℝ^V
    ↓
クロスエントロピー損失
```

**数値安定性：**

Softmaxは数値的に不安定なので、Log-Softmaxを使用：

$$\log P(w_t = k) = z_k - \log\sum_{j=1}^{V} \exp(z_j)$$

さらに、LogSumExpトリック：

$$\log\sum_{j} \exp(z_j) = m + \log\sum_{j} \exp(z_j - m)$$

ここで $m = \max_j z_j$

---

## 7.2 クロスエントロピー損失の情報理論的解釈

### 7.2.1 クロスエントロピーの定義

**定義：**

真の分布 $p$ とモデル分布 $q$ の間のクロスエントロピー：

$$H(p, q) = -\mathbb{E}_{x \sim p}[\log q(x)] = -\sum_x p(x)\log q(x)$$

**言語モデルでの適用：**

- $p$：データの真の分布（one-hot）
- $q$：モデルの予測分布

$$\mathcal{L}_{\text{CE}} = -\sum_t \log P_\theta(w_t | w_{<t})$$

### 7.2.2 KLダイバージェンスとの関係

**KLダイバージェンス：**

$$D_{\text{KL}}(p \| q) = \sum_x p(x)\log\frac{p(x)}{q(x)} = H(p, q) - H(p)$$

**重要な関係：**

$$H(p, q) = H(p) + D_{\text{KL}}(p \| q)$$

**含意：**

クロスエントロピーを最小化 = KLダイバージェンスを最小化

$$\min_\theta H(p, q) \Leftrightarrow \min_\theta D_{\text{KL}}(p \| q)$$

（$H(p)$ はモデルに依存しないため）

**直感的理解：**

> モデル分布をデータ分布に近づける

### 7.2.3 エントロピーの下界

**重要な性質：**

$$H(p, q) \geq H(p)$$

等号成立は $p = q$ のとき

**意味：**

> クロスエントロピーの最小値は、データのエントロピー

**英語テキストの例：**

データのエントロピー：約1.1 bits/文字（Shannon, 1951）

理想的なモデル：$H(p, q) = 1.1$ bits/文字

現実的なモデル：$H(p, q) \approx 1.5$-$2.0$ bits/文字

→ まだ改善の余地あり！

### 7.2.4 パープレキシティとの対応

**パープレキシティ：**

$$\text{PPL} = 2^{H(p,q)}$$

（底が2の場合）

または

$$\text{PPL} = e^{H(p,q)}$$

（自然対数の場合）

**解釈：**

> 「平均的な分岐数」

**例：**

```
H = 1 bit/token → PPL = 2 (2択)
H = 3 bits/token → PPL = 8 (8択)
H = 10 bits/token → PPL = 1024 (1024択)
```

---

## 7.3 Adam最適化アルゴリズムの収束理論

### 7.3.1 Adamの動機

**SGDの問題点：**

1. 学習率の選択が困難
2. すべてのパラメータに同じ学習率
3. 勾配のノイズに敏感

**Adamの改善：**

1. 適応的な学習率（パラメータごと）
2. モーメンタム（慣性）
3. 勾配の二乗の移動平均

### 7.3.2 Adamアルゴリズム

**パラメータ：**

- $\alpha$：学習率（例：0.001）
- $\beta_1$：1次モーメントの減衰率（例：0.9）
- $\beta_2$：2次モーメントの減衰率（例：0.999）
- $\epsilon$：数値安定性（例：$10^{-8}$）

**アルゴリズム：**

```
初期化:
  m₀ = 0  # 1次モーメント
  v₀ = 0  # 2次モーメント
  t = 0   # タイムステップ

for each iteration:
  t = t + 1
  gₜ = ∇θ L(θₜ₋₁)  # 勾配計算
  
  # モーメント更新
  mₜ = β₁·mₜ₋₁ + (1-β₁)·gₜ
  vₜ = β₂·vₜ₋₁ + (1-β₂)·gₜ²
  
  # バイアス補正
  m̂ₜ = mₜ / (1 - β₁ᵗ)
  v̂ₜ = vₜ / (1 - β₂ᵗ)
  
  # パラメータ更新
  θₜ = θₜ₋₁ - α · m̂ₜ / (√v̂ₜ + ε)
```

### 7.3.3 各コンポーネントの役割

**1次モーメント $m_t$（モーメンタム）：**

$$m_t = \beta_1 m_{t-1} + (1-\beta_1)g_t$$

**指数移動平均（EMA）：**

$$m_t \approx \frac{1}{1-\beta_1}\sum_{i=1}^{t} \beta_1^{t-i}g_i$$

$\beta_1 = 0.9$ の場合、直近約10ステップの平均

**効果：**

```
勾配が振動する場合:
  ↗ ↘ ↗ ↘ ↗ ↘
  
モーメンタム:
  → → → (平滑化)
  
→ 安定した更新
```

**2次モーメント $v_t$：**

$$v_t = \beta_2 v_{t-1} + (1-\beta_2)g_t^2$$

**効果：**

大きく変動するパラメータ → 小さい学習率
小さく変動するパラメータ → 大きい学習率

**視覚化：**

```
パラメータA: 勾配が大きい
  → vₜ大 → 学習率小 → 慎重に更新

パラメータB: 勾配が小さい
  → vₜ小 → 学習率大 → 積極的に更新
```

**バイアス補正：**

初期ステップでは $m_0 = v_0 = 0$ なので、推定が0にバイアス

$$\hat{m}_t = \frac{m_t}{1 - \beta_1^t}, \quad \hat{v}_t = \frac{v_t}{1 - \beta_2^t}$$

**例（$\beta_1 = 0.9$）：**

```
t=1: 1/(1-0.9¹) = 10
t=2: 1/(1-0.9²) = 5.26
t=10: 1/(1-0.9¹⁰) ≈ 1.54
t→∞: → 1 (補正不要)
```

### 7.3.4 収束の理論

**定理（簡略版）：**

適切な条件下で、Adamは以下のレートで収束：

$$\frac{1}{T}\sum_{t=1}^{T} \mathbb{E}[\|\nabla f(\theta_t)\|^2] = O\left(\frac{1}{\sqrt{T}}\right)$$

**条件：**

1. 勾配の有界性
2. 滑らかな目的関数
3. 適切なハイパーパラメータ

**実践的な含意：**

- 非凸問題でも良好に機能
- 停留点（局所最小値、鞍点）に収束
- 大域最小値の保証なし（しかし実際には問題ない）

### 7.3.5 AdamWとの違い

**問題：Adamでの重み減衰（weight decay）**

$$\theta_t = \theta_{t-1} - \alpha \cdot \frac{m_t}{\sqrt{v_t}} - \lambda\theta_{t-1}$$

L2正則化と等価**ではない**！

**AdamW（修正版）：**

重み減衰を適応的学習率の外に

$$\theta_t = (1-\lambda)\theta_{t-1} - \alpha \cdot \frac{m_t}{\sqrt{v_t}}$$

**LLMでの使用：**

ほぼすべての最新LLMがAdamWを使用（GPT-3, GPT-4, LLaMA, ...）

---

## 7.4 学習率スケジューリングの根拠

### 7.4.1 学習率の重要性

**問題：固定学習率**

```
学習率が大きすぎる:
  Loss
    \  /\  /\
     \/  \/   振動、発散
     
学習率が小さすぎる:
  Loss
    \_____ 収束が遅い
```

**解決策：動的な学習率**

訓練の進行に応じて調整

### 7.4.2 ウォームアップ（Warmup）

**線形ウォームアップ：**

$$\eta_t = \eta_{\max} \cdot \min\left(1, \frac{t}{T_{\text{warmup}}}\right)$$

**視覚化：**

```
学習率
  ↑
ηmax|      __________
    |     /
    |    /
    |   /
    |  /
  0 |_/_______________→ ステップ
    0  Twarmup
```

**なぜ必要？**

1. **パラメータの初期化**
   - ランダム初期化から急激に更新すると不安定
   - 小さい学習率で慎重にスタート

2. **Adam統計の安定化**
   - $m_t, v_t$ が0から始まる
   - 初期ステップで安定した推定が必要

3. **勾配の大きさ**
   - 初期の勾配は大きくなりがち
   - 小さい学習率で緩和

**典型的な設定：**

```
GPT-2: 375M steps
  Warmup: 2,000 steps (約0.5%)

GPT-3: 300B tokens
  Warmup: 初期の数%
  
LLaMA: 1T tokens
  Warmup: 2,000 steps
```

### 7.4.3 コサイン減衰

**コサインアニーリング：**

$$\eta_t = \eta_{\min} + \frac{\eta_{\max} - \eta_{\min}}{2}\left(1 + \cos\left(\frac{t - T_{\text{warmup}}}{T_{\max} - T_{\text{warmup}}}\pi\right)\right)$$

**視覺化：**

```
学習率
  ↑
ηmax|  /‾‾‾‾‾‾‾‾\
    | /           \
    |/             \___
ηmin|__________________ → ステップ
    0  Twarmup    Tmax
```

**利点：**

1. 滑らかな減衰
2. 後半で小さい学習率 → 微調整
3. 数学的に美しい

**実装：**

```python
def cosine_schedule(step, warmup_steps, max_steps, eta_max, eta_min=0):
    if step < warmup_steps:
        # ウォームアップ
        return eta_max * step / warmup_steps
    else:
        # コサイン減衰
        progress = (step - warmup_steps) / (max_steps - warmup_steps)
        return eta_min + 0.5 * (eta_max - eta_min) * (1 + np.cos(np.pi * progress))
```

### 7.4.4 その他のスケジューリング

**1. 逆平方根減衰：**

$$\eta_t = \eta_{\max} \cdot \min\left(1, \frac{\sqrt{T_{\text{warmup}}}}{\sqrt{t}}\right)$$

Transformerオリジナル論文で使用

**2. 線形減衰：**

$$\eta_t = \eta_{\max} \cdot \max\left(0, \frac{T_{\max} - t}{T_{\max} - T_{\text{warmup}}}\right)$$

**3. 段階的減衰（Step Decay）：**

$$\eta_t = \eta_{\max} \cdot \gamma^{\lfloor t/T_{\text{step}}\rfloor}$$

例：30エポックごとに0.1倍

**GPT-3の設定：**

- ウォームアップ：375M tokens
- コサイン減衰：300B tokensまで
- 最小学習率：最大の10%

---

## 7.5 正則化手法の理論的基礎

### 7.5.1 過学習の問題

**過学習（Overfitting）：**

訓練データに過度に適合し、未知データで性能低下

```
訓練損失 vs 検証損失

Loss
  ↑
  |  訓練__
  |        ‾‾‾\___
  |  検証____/‾‾‾‾
  |           ↑
  |        過学習開始
  +───────────────→ エポック
```

**LLMでの過学習：**

意外と少ない！理由：
1. 膨大なパラメータ（数十億〜数千億）
2. 膨大なデータ（数百億〜数兆トークン）
3. 早期終了（データを1エポックしか使わない）

### 7.5.2 重み減衰（Weight Decay）

**L2正則化：**

$$\mathcal{L}_{\text{reg}} = \mathcal{L} + \frac{\lambda}{2}\sum_i \theta_i^2$$

**勾配：**

$$\nabla_\theta \mathcal{L}_{\text{reg}} = \nabla_\theta \mathcal{L} + \lambda\theta$$

**効果：**

重みを0に近づける → モデルの複雑さを制限

**AdamWでの実装：**

$$\theta_t = (1 - \lambda\alpha)\theta_{t-1} - \alpha \cdot \frac{m_t}{\sqrt{v_t}}$$

**典型的な値：**

```
GPT-2: λ = 0.01
GPT-3: λ = 0.1
LLaMA: λ = 0.1
```

### 7.5.3 ドロップアウト

**アイデア：**

訓練中、ランダムにニューロンを無効化

$$h_{\text{dropout}} = h \odot m, \quad m_i \sim \text{Bernoulli}(1-p)$$

ここで $p$ はドロップアウト率（例：0.1）

**効果：**

1. アンサンブル学習の近似
2. ニューロン間の共適応を防ぐ

**視覚化：**

```
通常:
  入力 → [●●●●●] → 出力

ドロップアウト (p=0.5):
  入力 → [●○●○●] → 出力
  
各バッチで異なるパターン
→ ロバストな特徴学習
```

**Transformerでの使用：**

複数箇所でドロップアウト：

1. **埋め込みドロップアウト**
2. **アテンションドロップアウト**
   $$\text{Attention} = \text{Dropout}(\text{softmax}(\cdots))$$
3. **残差ドロップアウト**
   $$h = h + \text{Dropout}(\text{SubLayer}(h))$$

**典型的な値：**

```
GPT-2: p = 0.1
BERT: p = 0.1
大規模LLM: p = 0.0 - 0.1（小さめ）
```

### 7.5.4 レイヤー正規化（再訪）

**正則化効果：**

Layer Normalizationも暗黙的な正則化

**メカニズム：**

1. 各層の出力を正規化
2. 極端な活性化を防ぐ
3. 勾配の流れを安定化

**実験的証拠：**

Layer Normなし → 過学習しやすい  
Layer Normあり → 汎化性能向上

### 7.5.5 データ拡張

**自然言語での課題：**

画像と違い、データ拡張が難しい

**可能な手法：**

1. **バックトランスレーション**
   ```
   英語 → 日本語 → 英語
   （パラフレーズ生成）
   ```

2. **ランダムマスキング**（BERTスタイル）
   ```
   元: "猫が魚を食べる"
   拡張: "猫が[MASK]を食べる"
   ```

3. **トークンの置換**
   ```
   元: "猫が魚を食べる"
   拡張: "犬が魚を食べる"（意味保持）
   ```

**LLMでは：**

通常、データ拡張を使わない
→ データ量が十分大きいため

### 7.5.6 Early Stopping

**アイデア：**

検証損失が悪化し始めたら訓練停止

**LLMでの実践：**

実はあまり使わない！理由：

1. **データが1エポックのみ**
   - 過学習する前に終了

2. **計算コストの制約**
   - 事前に訓練期間を決定

3. **継続的改善**
   - さらに訓練すれば改善し続ける

**代わりに：**

チェックポイントを保存し、後で最良のものを選択

```
保存: 10k, 20k, 30k, ... ステップごと
評価: 各チェックポイントで検証セット評価
選択: 最良の性能のチェックポイント
```

---

## 本章のまとめ

### 学んだこと

✅ **最尤推定**
- 言語モデリングの目的
- ネガティブ対数尤度損失
- クロスエントロピーとの関係

✅ **情報理論的解釈**
- KLダイバージェンス
- エントロピーの下界
- パープレキシティ

✅ **Adam最適化**
- 適応的学習率
- モーメンタムと2次モーメント
- バイアス補正

✅ **学習率スケジューリング**
- ウォームアップの必要性
- コサイン減衰
- 典型的な設定

✅ **正則化**
- 重み減衰（AdamW）
- ドロップアウト
- Layer Normalization

### 重要な公式

| 概念 | 公式 |
|------|------|
| NLL損失 | $\mathcal{L} = -\frac{1}{N}\sum_i \log P(w_i\|w_{<i})$ |
| クロスエントロピー | $H(p,q) = -\sum_x p(x)\log q(x)$ |
| Adam更新 | $\theta_t = \theta_{t-1} - \alpha \frac{m_t}{\sqrt{v_t}+\epsilon}$ |
| コサイン減衰 | $\eta_t = \eta_{\min} + \frac{\eta_{\max}-\eta_{\min}}{2}(1+\cos(\cdots))$ |
| 重み減衰 | $\theta_t = (1-\lambda\alpha)\theta_{t-1} - \cdots$ |

### 実践的なハイパーパラメータ

**Adam:**
- $\beta_1 = 0.9$
- $\beta_2 = 0.999$ (または0.95)
- $\epsilon = 10^{-8}$

**学習率:**
- 最大: $3 \times 10^{-4}$ (GPT-2/3)
- ウォームアップ: 2,000ステップ
- スケジューリング: コサイン減衰

**正則化:**
- 重み減衰: $\lambda = 0.1$
- ドロップアウト: $p = 0.0$-$0.1$

### 次章の予告

第8章では、**ファインチューニング**を学びます：
- 転移学習の理論
- ドメイン適応
- 破滅的忘却の問題
- 継続学習アルゴリズム

事前学習済みモデルを特定タスクに適応させる技術を理解していきます。

---

## 練習問題

### 問題1：クロスエントロピー
予測分布が $q = [0.7, 0.2, 0.1]$、真の分布が $p = [1, 0, 0]$（one-hot）のとき、クロスエントロピーを計算せよ。

### 問題2：Adam更新
$g_1 = 2$, $\beta_1 = 0.9$, $\beta_2 = 0.999$のとき、$m_1$と$\hat{m}_1$を計算せよ（$m_0 = 0$）。

### 問題3：学習率スケジュール
$\eta_{\max} = 0.001$, $T_{\text{warmup}} = 1000$, $t=500$のとき、線形ウォームアップでの学習率は？

### 問題4：ドロップアウト
層に100個のニューロンがあり、ドロップアウト率$p=0.1$のとき、平均的に何個のニューロンが有効？

### 解答

**問題1:**
$$H(p, q) = -\sum_i p_i \log q_i = -1 \times \log(0.7) = 0.357$$

**問題2:**
$$m_1 = 0.9 \times 0 + 0.1 \times 2 = 0.2$$
$$\hat{m}_1 = \frac{0.2}{1 - 0.9^1} = \frac{0.2}{0.1} = 2$$

**問題3:**
$$\eta_{500} = 0.001 \times \frac{500}{1000} = 0.0005$$

**問題4:**
$$(1 - 0.1) \times 100 = 90\text{個}$$

---

**📖 前章：[第6章 スケーリング法則の基礎](./第6章_スケーリング法則の基礎.md)**  
**📖 次章：[第8章 ファインチューニングの理論](./第8章_ファインチューニングの理論.md)**
